{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.optim\n",
    "from pyro.infer import *\n",
    "from torch.distributions import constraints\n",
    "from pyro import distributions as dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numbers\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "from six import add_metaclass\n",
    "\n",
    "import pyro.poutine as poutine\n",
    "from pyro.distributions import Categorical, Empirical\n",
    "from pyro.ops.stats import waic\n",
    "from pyro.infer.util import site_is_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorAnalysis(X):\n",
    "    N, D = X.shape\n",
    "    K = 2\n",
    "    locloc = 0.\n",
    "    locscale = 1.\n",
    "    scaleloc = 0.\n",
    "    scalescale = 1.\n",
    "    cov_factor_loc = torch.zeros(K,D)\n",
    "    cov_factor_scale = torch.ones(K,D)*10\n",
    "    with pyro.plate('D', D):\n",
    "        loc = pyro.sample('loc', dst.Normal(locloc, locscale))\n",
    "        cov_diag = pyro.sample('scale', dst.LogNormal(scaleloc, scalescale))\n",
    "        with pyro.plate('K', K):\n",
    "            cov_factor = pyro.sample('cov_factor', dst.Normal(cov_factor_loc,cov_factor_scale))\n",
    "        cov_factor = cov_factor.transpose(0,1)\n",
    "    with pyro.plate('N', N):\n",
    "        X = pyro.sample('obs', dst.LowRankMultivariateNormal(loc, cov_factor=cov_factor, cov_diag=cov_diag))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 800\n",
    "D = 5\n",
    "data = factorAnalysis(np.ones((N,D)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(X):\n",
    "    K, locloc, locscale, scaleloc, scalescale, cov_factor_loc, cov_factor_scale = 2,torch.zeros(D),torch.ones(D),torch.zeros(D),torch.ones(D),torch.zeros(1,D),torch.ones(1,D)*10\n",
    "    with pyro.plate('D', D, dim=-1):\n",
    "        loc_loc = pyro.param('loc_loc', locloc)\n",
    "        loc_scale = pyro.param('loc_scale', locscale, constraint=constraints.positive)\n",
    "        cov_diag_loc = pyro.param('scale_loc', scaleloc)\n",
    "        cov_diag_scale = pyro.param('scale_scale', scalescale, constraint=constraints.positive)\n",
    "        # sample variables\n",
    "        loc = pyro.sample('loc', dst.Normal(loc_loc,loc_scale))\n",
    "        with pyro.plate('K', K, dim=-2):\n",
    "            cov_factor_loc = pyro.param('cov_factor_loc_{}'.format(K), cov_factor_loc)\n",
    "            cov_factor_scale = pyro.param('cov_factor_scale_{}'.format(K), cov_factor_scale, constraint=constraints.positive)\n",
    "            cov_factor = pyro.sample('cov_factor', dst.Normal(cov_factor_loc, cov_factor_scale))\n",
    "        cov_factor = cov_factor.transpose(0,1)\n",
    "        cov_diag = pyro.sample('scale', dst.LogNormal(cov_diag_loc, cov_diag_scale))\n",
    "    return loc, cov_factor, cov_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_param_callable(module_name, param_name):\n",
    "    return {\"lr\": 0.01, 'betas': [0.9, 0.99]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned_model = pyro.condition(factorAnalysis, data = {'obs': data})\n",
    "optim = pyro.optim.Adam(per_param_callable)\n",
    "elbo = Trace_ELBO()\n",
    "svi = SVI(conditioned_model, guide, optim, loss=elbo,num_steps=1000, num_samples=100).run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-483e75d463c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrace_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTracePredictive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorAnalysis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/abstract_infer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0mchain_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/abstract_infer.py\u001b[0m in \u001b[0;36m_traces\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mmodel_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_dropped_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mresampled_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresampled_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/abstract_infer.py\u001b[0m in \u001b[0;36m_adjust_to_data\u001b[0;34m(self, trace, data_trace)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;31m# and prediction data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mocis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msite_is_subsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 subsampled_idxs[cis.name] = subsampled_idxs.get(cis.name,\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trace_pred = TracePredictive(factorAnalysis, svi, num_samples=1000).run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracePredictive(TracePosterior):\n",
    "    \"\"\"\n",
    "    Generates and holds traces from the posterior predictive distribution,\n",
    "    given model execution traces from the approximate posterior. This is\n",
    "    achieved by constraining latent sites to randomly sampled parameter\n",
    "    values from the model execution traces and running the model forward\n",
    "    to generate traces with new response (\"_RETURN\") sites.\n",
    "    :param model: arbitrary Python callable containing Pyro primitives.\n",
    "    :param TracePosterior posterior: trace posterior instance holding samples from the model's approximate posterior.\n",
    "    :param int num_samples: number of samples to generate.\n",
    "    :param keep_sites: The sites which should be sampled from posterior distribution (default: all)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, posterior, num_samples, keep_sites=None):\n",
    "        self.model = model\n",
    "        self.posterior = posterior\n",
    "        self.num_samples = num_samples\n",
    "        self.keep_sites = keep_sites\n",
    "        super(TracePredictive, self).__init__()\n",
    "\n",
    "    def _traces(self, *args, **kwargs):\n",
    "        if not self.posterior.exec_traces:\n",
    "            self.posterior.run(*args, **kwargs)\n",
    "        data_trace = poutine.trace(self.model).get_trace(*args, **kwargs)\n",
    "        for _ in range(self.num_samples):\n",
    "            model_trace = self.posterior().copy()\n",
    "            self._remove_dropped_nodes(model_trace)\n",
    "            self._adjust_to_data(model_trace, data_trace)\n",
    "            resampled_trace = poutine.trace(poutine.replay(self.model, model_trace)).get_trace(*args, **kwargs)\n",
    "            yield (resampled_trace, 0., 0)\n",
    "\n",
    "    def _remove_dropped_nodes(self, trace):\n",
    "        if self.keep_sites is None:\n",
    "            return\n",
    "        for name, site in list(trace.nodes.items()):\n",
    "            if name not in self.keep_sites:\n",
    "                trace.remove_node(name)\n",
    "                continue\n",
    "\n",
    "    def _adjust_to_data(self, trace, data_trace):\n",
    "        subsampled_idxs = dict()\n",
    "        for name, site in trace.iter_stochastic_nodes():\n",
    "            # Adjust subsample sites\n",
    "            if site_is_subsample(site):\n",
    "                site[\"fn\"] = data_trace.nodes[name][\"fn\"]\n",
    "                site[\"value\"] = data_trace.nodes[name][\"value\"]\n",
    "            # Adjust sites under conditionally independent stacks\n",
    "            orig_cis_stack = site[\"cond_indep_stack\"]\n",
    "            site[\"cond_indep_stack\"] = data_trace.nodes[name][\"cond_indep_stack\"]\n",
    "            assert len(orig_cis_stack) == len(site[\"cond_indep_stack\"])\n",
    "            site[\"fn\"] = data_trace.nodes[name][\"fn\"]\n",
    "            for ocis, cis in zip(orig_cis_stack, site[\"cond_indep_stack\"]):\n",
    "                # Select random sub-indices to replay values under conditionally independent stacks.\n",
    "                # Otherwise, we assume there is an dependence of indexes between training data\n",
    "                # and prediction data.\n",
    "                assert ocis.name == cis.name\n",
    "                if site_is_subsample(site):\n",
    "                    batch_dim = cis.dim\n",
    "                    subsampled_idxs[cis.name] = torch.randint(0, site['value'].size(batch_dim), (cis.size,),device=site[\"value\"].device)\n",
    "                else:    \n",
    "                    batch_dim = cis.dim - site[\"fn\"].event_dim\n",
    "                    subsampled_idxs[cis.name] = subsampled_idxs.get(cis.name,\n",
    "                                                                torch.randint(0, ocis.size, (cis.size,),\n",
    "                                                                              device=site[\"value\"].device))\n",
    "                    site[\"value\"] = site[\"value\"].index_select(batch_dim, subsampled_idxs[cis.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_pred = TracePredictive(factorAnalysis, svi, num_samples=1000).run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 800, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_pred.marginal().support()['_RETURN'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
